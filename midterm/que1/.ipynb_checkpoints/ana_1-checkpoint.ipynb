{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 1\n",
    "- Created a list containing most frequently used frdulent words\n",
    "- Read each mail between 1999-2001 of top convicts and storing words from email in a list\n",
    "- Comparing the email words with fradulent words and calculating their total occurrence for all convicts\n",
    "- Sorting and displaying top 5 fradulent words that top convicts used between 1999-2001\n",
    "- Plotting a chart to display the collected information visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing the required modules\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import nltk\n",
    "import operator\n",
    "import datetime\n",
    "import email.utils\n",
    "import numpy as np # Used only for arranging y axis values on graph plotted\n",
    "from email.parser import Parser \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_employees = ['lay-k', 'skilling-j', 'whalley-g'] # Prepared a list for convicts directories\n",
    "\n",
    "emp_msg_list = [] # Creating an empty list to store employee names and their emails\n",
    "\n",
    "emp_name_list = [] # Creating an empty list which will store employee name and local path for source directory\n",
    "\n",
    "for emp in all_employees: # Looping through all employees\n",
    "    filepath_emp = '~\\\\midterm\\\\data\\\\enron\\\\maildir\\\\' + emp # Creating path to employee directory\n",
    "    filepath_actual = os.path.expanduser(filepath_emp) # Creating actual path acccording to OS\n",
    "    emp_name_list.append([emp,filepath_actual]) # Populating the list with emp name and their directory path\n",
    "\n",
    "for emp, emp_path in emp_name_list: # Looping through each employee and their directory\n",
    "    for subdir, dirs, files in os.walk(emp_path): # Looping through each files present under directories and sub directories\n",
    "        for file in files: # Looping through each found directories, subdirectories or files\n",
    "            if(file[0] != '.'): # If selected file is a file and not a directory\n",
    "                \n",
    "                try: # Putting whole code in a try except block to catch unwanted errors\n",
    "                    response = open(os.path.join(subdir, file), 'r', errors = 'ignore') # Extracting the email\n",
    "                    email_emp = Parser().parsestr(response.read()) # Parsing the extracted email\n",
    "                    \n",
    "                    email_date = email.utils.parsedate(email_emp['Date']) # Extracting the date from parsed email\n",
    "                    \n",
    "                    if email_date[0] in [1999, 2000, 2001]: # Putting a check for emails through 1999-2001\n",
    "                        # Removing all punctuations after tokenizing the email body\n",
    "                        remove_punctuations=[re.sub(r'[^A-Za-z0-9]+','', x) for x in nltk.word_tokenize(email_emp.get_payload())]\n",
    "                        # Removing empty strings, if any\n",
    "                        remove_empty_string = [x for x in remove_punctuations if x] \n",
    "                        # Populating the list with emaildate and words from email\n",
    "                        emp_msg_list.append((email_date[0], remove_empty_string)) \n",
    "                        \n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_emp = 0 # Creating a temporary variable and assigning value 0 to it\n",
    "# Creating a list which contains most occurring fradulent words in scams worldwide\n",
    "suspicious_keywords = ['criminal', 'offence', 'violation', 'illegal', 'investment', 'inspection', 'earning', 'payment', 'cover']\n",
    "# Creating a list to store emaildate, freadulent words and its count from tokenized email of an employee\n",
    "suspicious_keywords_list = []\n",
    "\n",
    "for x, y in emp_msg_list: # Looping through each date and words used in emails on that date\n",
    "    for a in suspicious_keywords: # Looping through each fradulent words\n",
    "        for z in y: # Looping through each word of a email of particular date\n",
    "            if z.lower() == a: # If word is same as fraudulent word\n",
    "                count_emp = count_emp + 1 # Increment the temp count by 1\n",
    "            else: # If word not same as fraudulent word\n",
    "                continue # Goto next word\n",
    "        if count_emp > 0: # If tem count > 0, it means that is a fradulent word\n",
    "            suspicious_keywords_list.append([x, a, count_emp]) # Add that word alongwith its frequency in a dictionary\n",
    "        count_emp = 0 # Reassign temp count to 0 for outer for loop\n",
    "\n",
    "count_emp_final = 0 # Creating a temporary variable and assigning value 0 to it\n",
    "consolidated_dict = {} # Creating an empty dictionary to store fradulent words alongwith its frequency for all employees listed\n",
    "\n",
    "for x in suspicious_keywords: # Looping through each fradulent word\n",
    "    # Looping through each fradulent word to calculate its total sum as they can occur more than once in an email\n",
    "    for y in suspicious_keywords_list: \n",
    "        if x == y[1]:\n",
    "            count_emp_final = count_emp_final + y[2] # Calculating total sum of a fradulent word    \n",
    "    consolidated_dict.update({x:count_emp_final}) # Add fradulent words and their total frequency in a dictionary\n",
    "    count_emp_final = 0 # Reassiging the temp variable to 0 for outer for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sorting the dictionary in descending order of frequency\n",
    "consolidate_dict_sorted = sorted(consolidated_dict.items(), key=operator.itemgetter(1), reverse = True)\n",
    "\n",
    "# Displaying top 5 results\n",
    "print(consolidate_dict_sorted[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_values = [x[1] for x in consolidate_dict_sorted[:5]] # Storing top 5 frequencies to be used for y-axis\n",
    "x_values = [y[0] for y in consolidate_dict_sorted[:5]] # Storing top 5 words to be used for x-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure() # Calling the figure function from matplotlib module\n",
    "ax = fig.add_subplot(111) # Creating a subplot\n",
    "ax.set_title(\"Top five Fradulent words distribution\") # Setting up the title for plot\n",
    "\n",
    "width = .35 # Setting the width between each element of histogram\n",
    "ind = np.arange(len(y_values)) # Arranging the frequencies on y axis\n",
    "plt.bar(ind, y_values, width=width) # Plotting the chart\n",
    "plt.xticks(ind + width / 2, x_values) # Displaying the tick in the middle on x axis\n",
    "\n",
    "fig.autofmt_xdate() # Formatting the x axis to make values readable\n",
    "\n",
    "# Creating a path to store the created chart\n",
    "save_path = os.path.expanduser('~\\\\midterm\\\\que1\\\\ana_1\\\\Top five Fradulent words distribution.pdf') \n",
    "\n",
    "plt.savefig(save_path) # Saving the chart to desired location\n",
    " \n",
    "plt.show() # Displaying the chart"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
